{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "In this project, you will perform a logistic regression on the admissions data we've been working with in projects 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our first step will be to import the packages we need\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige\n",
      "0      0  380.0  3.61       3.0\n",
      "1      1  660.0  3.67       3.0\n",
      "2      1  800.0  4.00       1.0\n",
      "3      1  640.0  3.19       4.0\n",
      "4      0  520.0  2.93       4.0\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"admissions.csv\") #read in data\n",
    "df = df_raw.dropna() #drop null records\n",
    "print df.head() #print first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are our data counts\n",
      "admit       397\n",
      "gre         397\n",
      "gpa         397\n",
      "prestige    397\n",
      "dtype: int64\n",
      "\n",
      "Here is the shape of our data\n",
      "(397, 4)\n",
      "\n",
      "Here are our data set's summary stats\n",
      "            admit         gre         gpa    prestige\n",
      "count  397.000000  397.000000  397.000000  397.000000\n",
      "mean     0.317380  587.858942    3.392242    2.488665\n",
      "std      0.466044  115.717787    0.380208    0.947083\n",
      "min      0.000000  220.000000    2.260000    1.000000\n",
      "25%      0.000000  520.000000    3.130000    2.000000\n",
      "50%      0.000000  580.000000    3.400000    2.000000\n",
      "75%      1.000000  660.000000    3.670000    3.000000\n",
      "max      1.000000  800.000000    4.000000    4.000000\n"
     ]
    }
   ],
   "source": [
    "# Let's create some summary stat/counts to get an idea of what our data looks like\n",
    "\n",
    "counts = df.count() #Count the number of records. This will help us see if there are any null records.\n",
    "shape = df.shape #Show the shape of our data frame.\n",
    "summary_stats = df.describe() #Show a summary of our data, including counts, means, standard deviations, and quartiles\n",
    "\n",
    "print \"Here are our data counts\"\n",
    "print counts\n",
    "print \"\" #I printed blank rows so there was a demarkation between each of the segments\n",
    "print \"Here is the shape of our data\"\n",
    "print shape\n",
    "print \"\" #I printed blank rows so there was a demarkation between each of the segments\n",
    "print \"Here are our data set's summary stats\"\n",
    "print summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before we go any further, let's create a data dictionary\n",
    "\n",
    "Outcome/Covariate | Variable | Description | Type of Variable\n",
    "--- | ---| ---| ---\n",
    "outcome | admit | 0 = No, 1 = Yes | categorial/discrete\n",
    "covariate | gre | GRE score for the applicant | categorial/discrete\n",
    "covariate | gpa| GPA for the applicant | continuous\n",
    "covariate | prestige | How prestigious the applicant's undergraduate school is. 1 is the highest and 4 is the lowest | categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Frequency Tables\n",
    "\n",
    "#### 1. Let's create a frequency table of our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prestige  1.0  2.0  3.0  4.0\n",
      "admit                       \n",
      "0          28   95   93   55\n",
      "1          33   53   28   12\n"
     ]
    }
   ],
   "source": [
    "# frequency table for prestige and whether or not someone was admitted\n",
    "# The cross tab function will allow us to take our data frame and aggregate / pivot the data based on our variables of interest\n",
    "\n",
    "print pd.crosstab(df['admit'], df['prestige'], rownames=['admit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x115db0890>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEQCAYAAABLMTQcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4y5JDTLuktQg4y5JDTLuktSg/wPeZ1cJ/cMQ6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115f631d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualize this data by looking at a bar chart of admissions rates based on undergraduate prestige\n",
    "# We can clearly see from the output that as a school as a worse prestige level (which in this case is an increased prestige level, admissions rate decreases)\n",
    "\n",
    "df.groupby('prestige').admit.mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Return of dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create class or dummy variables for prestige "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prestige_1.0  prestige_2.0  prestige_3.0  prestige_4.0\n",
      "0             0             0             1             0\n",
      "1             0             0             1             0\n",
      "2             1             0             0             0\n",
      "3             0             0             0             1\n",
      "4             0             0             0             1\n"
     ]
    }
   ],
   "source": [
    "# create a dummy variable for prestige\n",
    "# to do this, I will use Panda's get_dummies function to create a dummy variable for each of the prestige levels\n",
    "\n",
    "dummy_ranks = pd.get_dummies(df['prestige'], prefix='prestige')\n",
    "print dummy_ranks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.join(dummy_ranks) #Join in dummy variables, so that it's back into the original data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige  prestige_1.0  prestige_2.0  prestige_3.0  \\\n",
       "0      0  380.0  3.61       3.0             0             0             1   \n",
       "1      1  660.0  3.67       3.0             0             0             1   \n",
       "2      1  800.0  4.00       1.0             1             0             0   \n",
       "3      1  640.0  3.19       4.0             0             0             0   \n",
       "4      0  520.0  2.93       4.0             0             0             0   \n",
       "\n",
       "   prestige_4.0  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #print the first few rows of the updated data frame, which added in the prestige dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are our updated data counts\n",
      "admit           397\n",
      "gre             397\n",
      "gpa             397\n",
      "prestige        397\n",
      "prestige_1.0    397\n",
      "prestige_2.0    397\n",
      "prestige_3.0    397\n",
      "prestige_4.0    397\n",
      "dtype: int64\n",
      "\n",
      "Here is the updated shape of our data\n",
      "(397, 8)\n"
     ]
    }
   ],
   "source": [
    "# Let's do some updated counts to ensure that we did everything correctly\n",
    "updated_counts = df.count()\n",
    "updated_shape = df.shape\n",
    "\n",
    "print \"Here are our updated data counts\" # We can now see that there's 397 records for our dummy variables\n",
    "print updated_counts\n",
    "print \"\" #I printed blank rows so there was a demarkation between each of the segments\n",
    "print \"Here is the updated shape of our data\"\n",
    "print updated_shape #We can see that we now have 4 additional columns (original shape was 397,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 When modeling our class variables, how many do we need? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: In general, we only need n-1 class variables, where n is the number of distinct values in the variable you want to create a dummy variable from. In this case, there are 4 possible \"prestige\" values, 1 - 4, but we really only need 3, since if you have `prestige 1` , `prestige 2`, and `prestigeg 3`, you can infer which records are `prestige 4` based on the other 3 dummy variables. Therefore, for this exercise, to model our class variables, we only need 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Hand calculating odds ratios\n",
    "\n",
    "Develop your intuition about expected outcomes by hand calculating odds ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige_1.0  prestige_2.0  prestige_3.0  prestige_4.0\n",
      "0      0  380.0  3.61             0             0             1             0\n",
      "1      1  660.0  3.67             0             0             1             0\n",
      "2      1  800.0  4.00             1             0             0             0\n",
      "3      1  640.0  3.19             0             0             0             1\n",
      "4      0  520.0  2.93             0             0             0             1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thshih/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Let's update our data frame to only include the columns we need\n",
    "\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "handCalc = df[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_1':])\n",
    "print handCalc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prestige  1.0  2.0  3.0  4.0\n",
      "admit                       \n",
      "0          28   95   93   55\n",
      "1          33   53   28   12\n"
     ]
    }
   ],
   "source": [
    "# The below exercises require our crosstab, so here it is again\n",
    "# crosstab prestige 1 admission \n",
    "# frequency table cutting prestige and whether or not someone was admitted\n",
    "print pd.crosstab(df['admit'], df['prestige'], rownames=['admit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Use the cross tab above to calculate the odds of being admitted to grad school if you attended a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.540983606557\n"
     ]
    }
   ],
   "source": [
    "# The odds of being admitted are (admitted / (admitted + not admitted)). We will want to only look at these values for top prestige schools\n",
    "\n",
    "odds_top_school = 33.0 / (33+28) #33.0 will turn this into a float so it presents the decimals\n",
    "print odds_top_school"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Now calculate the odds of admission if you did not attend a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.276785714286\n"
     ]
    }
   ],
   "source": [
    "# The odds of not being admitted are (admitted / (admitted + not admitted)). We will want to only look at these values now for those that didn't attent a top prestige schools\n",
    "\n",
    "odds_not_top_school = (53.0 + 28 + 12) / (95 + 93 + 55 + 53 + 28 + 12)\n",
    "print odds_not_top_school"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Calculate the odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17857142857\n",
      "0.382716049383\n"
     ]
    }
   ],
   "source": [
    "# Odds ratio is the odds / (1-odds)\n",
    "\n",
    "odds_ratio_top_school = 0.540983606557 / (1-0.540983606557)\n",
    "print odds_ratio_top_school\n",
    "\n",
    "odds_ratio_not_top_school = 0.276785714286 / (1-0.276785714286)\n",
    "print odds_ratio_not_top_school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.612903225804513"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the odds ratio for being admitted if you're not from a top school is < 1, let's normalize that\n",
    "\n",
    "1 / 0.382716049383"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Write this finding in a sentenance: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "Your odds of getting into grad school if you attended a top \"Prestige 1\" undergraduate school is 1.17:1\n",
    "\n",
    "Your odds of getting into grad school if you didn't attend a top \"Prestige 1\" undergraduate school is 1:2.61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Print the cross tab for prestige_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prestige  1.0  2.0  3.0  4.0\n",
      "admit                       \n",
      "0          28   95   93   55\n",
      "1          33   53   28   12\n"
     ]
    }
   ],
   "source": [
    "print pd.crosstab(df['admit'], df['prestige'], rownames=['admit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Calculate the OR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.218181818182\n"
     ]
    }
   ],
   "source": [
    "odds_bottom_school = 12.0/(12+55)\n",
    "odds_not_botton_school = (33.0+53+28) / (33+53+28+28+95+93)\n",
    "odds_ratio = odds_bottom_school / (1-odds_bottom_school)\n",
    "\n",
    "print odds_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.583333333329514"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized odds ratio\n",
    "\n",
    "1/0.218181818182\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 3.7 Write this finding in a sentence\n",
    "\n",
    "Answer: The odds of getting into grad school if you went to a \"prestige 4\" tier school are 0.22:1. Normalized, the odds of getting in are 1:4.58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0\n",
      "0      0  380.0  3.61             0             1             0\n",
      "1      1  660.0  3.67             0             1             0\n",
      "2      1  800.0  4.00             0             0             0\n",
      "3      1  640.0  3.19             0             0             1\n",
      "4      0  520.0  2.93             0             0             1\n"
     ]
    }
   ],
   "source": [
    "# create a clean data frame for the regression\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "data = df[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_2':])\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to add a constant term for our Logistic Regression. The statsmodels function we're going to be using requires that intercepts/constants are specified explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# manually add the intercept\n",
    "data['intercept'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Set the covariates to a variable called train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our covariates are everything from GRE onward, so we can use python's 0 index to indicate we want everything from column 1 onward\n",
    "\n",
    "train_cols = data.columns[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573854\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# this will fit the data based on our training columns & our outcome variable, \"admit\"\n",
    "# Stasmodel Logit is a program that will help us create a logistic regression results output\n",
    "\n",
    "model_fit = sm.Logit(data['admit'], data[train_cols])\n",
    "model_result = model_fit.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Print the summary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   No. Observations:                  397\n",
      "Model:                          Logit   Df Residuals:                      391\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Tue, 22 Aug 2017   Pseudo R-squ.:                 0.08166\n",
      "Time:                        18:05:34   Log-Likelihood:                -227.82\n",
      "converged:                       True   LL-Null:                       -248.08\n",
      "                                        LLR p-value:                 1.176e-07\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "gre              0.0022      0.001      2.028      0.043    7.44e-05       0.004\n",
      "gpa              0.7793      0.333      2.344      0.019       0.128       1.431\n",
      "prestige_2.0    -0.6801      0.317     -2.146      0.032      -1.301      -0.059\n",
      "prestige_3.0    -1.3387      0.345     -3.882      0.000      -2.015      -0.663\n",
      "prestige_4.0    -1.5534      0.417     -3.721      0.000      -2.372      -0.735\n",
      "intercept       -3.8769      1.142     -3.393      0.001      -6.116      -1.638\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# This will print a logistic regression summary based on the model_result variable we created above\n",
    "print model_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Calculate the odds ratios of the coeffiencents and their 95% CI intervals\n",
    "\n",
    "hint 1: np.exp(X)\n",
    "\n",
    "hint 2: conf['OR'] = params\n",
    "        \n",
    "           conf.columns = ['2.5%', '97.5%', 'OR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gre             1.002221\n",
      "gpa             2.180027\n",
      "prestige_2.0    0.506548\n",
      "prestige_3.0    0.262192\n",
      "prestige_4.0    0.211525\n",
      "intercept       0.020716\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Odds ratios\n",
    "\n",
    "print np.exp(model_result.params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  2.5%     97.5%        OR\n",
      "gre           1.000074  1.004372  1.002221\n",
      "gpa           1.136120  4.183113  2.180027\n",
      "prestige_2.0  0.272168  0.942767  0.506548\n",
      "prestige_3.0  0.133377  0.515419  0.262192\n",
      "prestige_4.0  0.093329  0.479411  0.211525\n",
      "intercept     0.002207  0.194440  0.020716\n"
     ]
    }
   ],
   "source": [
    "#Odds ratios with the 95% confidence interval\n",
    "\n",
    "params = model_result.params\n",
    "conf = model_result.conf_int()\n",
    "conf['OR'] = params\n",
    "conf.columns = ['2.5%', '97.5%', 'OR']\n",
    "print np.exp(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Interpret the OR of Prestige_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Interpret the OR of GPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Predicted probablities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way of evaluating our classifier, we're going to recreate the dataset with every logical combination of input values. This will allow us to see how the predicted probability of admission increases/decreases across different variables. First we're going to generate the combinations using a helper function called cartesian (above).\n",
    "\n",
    "We're going to use np.linspace to create a range of values for \"gre\" and \"gpa\". This creates a range of linearly spaced values from a specified min and maximum value--in our case just the min/max observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cartesian(arrays, out=None):\n",
    "    \"\"\"\n",
    "    Generate a cartesian product of input arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "    \"\"\"\n",
    "\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    n = np.prod([x.size for x in arrays])\n",
    "    if out is None:\n",
    "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
    "\n",
    "    m = n / arrays[0].size\n",
    "    out[:,0] = np.repeat(arrays[0], m)\n",
    "    if arrays[1:]:\n",
    "        cartesian(arrays[1:], out=out[0:m,1:])\n",
    "        for j in xrange(1, arrays[0].size):\n",
    "            out[j*m:(j+1)*m,1:] = out[0:m,1:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 220.          284.44444444  348.88888889  413.33333333  477.77777778\n",
      "  542.22222222  606.66666667  671.11111111  735.55555556  800.        ]\n",
      "[ 2.26        2.45333333  2.64666667  2.84        3.03333333  3.22666667\n",
      "  3.42        3.61333333  3.80666667  4.        ]\n"
     ]
    }
   ],
   "source": [
    "# instead of generating all possible values of GRE and GPA, we're going\n",
    "# to use an evenly spaced range of 10 values from the min to the max \n",
    "gres = np.linspace(data['gre'].min(), data['gre'].max(), 10)\n",
    "print gres\n",
    "# array([ 220.        ,  284.44444444,  348.88888889,  413.33333333,\n",
    "#         477.77777778,  542.22222222,  606.66666667,  671.11111111,\n",
    "#         735.55555556,  800.        ])\n",
    "gpas = np.linspace(data['gpa'].min(), data['gpa'].max(), 10)\n",
    "print gpas\n",
    "# array([ 2.26      ,  2.45333333,  2.64666667,  2.84      ,  3.03333333,\n",
    "#         3.22666667,  3.42      ,  3.61333333,  3.80666667,  4.        ])\n",
    "\n",
    "\n",
    "# enumerate all possibilities\n",
    "combos = pd.DataFrame(cartesian([gres, gpas, [1, 2, 3, 4], [1.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Recreate the dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recreate the dummy variables\n",
    "\n",
    "# keep only what we need for making predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Make predictions on the enumerated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Interpret findings for the last 4 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Plot the probability of being admitted into graduate school, stratified by GPA and GRE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
